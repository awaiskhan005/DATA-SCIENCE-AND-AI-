{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/awaiskhan005/DATA-SCIENCE-AND-AI-/blob/main/iSREAL_PROJECT_2ND.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NQjxtVgp38Bv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, classification_report\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMcb4MS4_tHn",
        "outputId": "a8a9f6ed-96b7-44b7-e6be-239995e46368"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 56050 entries, 0 to 56049\n",
            "Data columns (total 44 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   x1      56050 non-null  float64\n",
            " 1   x2      56050 non-null  float64\n",
            " 2   x3      56050 non-null  float64\n",
            " 3   x4      56050 non-null  float64\n",
            " 4   x5      56050 non-null  float64\n",
            " 5   x6      56050 non-null  float64\n",
            " 6   x7      56050 non-null  int64  \n",
            " 7   x8      56050 non-null  int64  \n",
            " 8   x9      56050 non-null  int64  \n",
            " 9   x10     56050 non-null  int64  \n",
            " 10  x11     56050 non-null  int64  \n",
            " 11  x12     56050 non-null  int64  \n",
            " 12  x13     56050 non-null  int64  \n",
            " 13  x14     56050 non-null  int64  \n",
            " 14  x15     56050 non-null  int64  \n",
            " 15  x16     56050 non-null  int64  \n",
            " 16  x17     56050 non-null  int64  \n",
            " 17  x18     56050 non-null  int64  \n",
            " 18  x19     56050 non-null  int64  \n",
            " 19  x20     56050 non-null  float64\n",
            " 20  x21     56050 non-null  int64  \n",
            " 21  x22     56050 non-null  float64\n",
            " 22  x23     56050 non-null  float64\n",
            " 23  x24     56050 non-null  float64\n",
            " 24  x25     56050 non-null  int64  \n",
            " 25  x26     56050 non-null  int64  \n",
            " 26  x27     56050 non-null  float64\n",
            " 27  x28     56050 non-null  float64\n",
            " 28  x29     56050 non-null  float64\n",
            " 29  x30     56050 non-null  float64\n",
            " 30  x31     56050 non-null  float64\n",
            " 31  x32     56050 non-null  float64\n",
            " 32  x33     56050 non-null  float64\n",
            " 33  x34     56050 non-null  float64\n",
            " 34  x35     56050 non-null  float64\n",
            " 35  x36     56050 non-null  float64\n",
            " 36  x37     56050 non-null  float64\n",
            " 37  x38     56050 non-null  float64\n",
            " 38  x39     56050 non-null  float64\n",
            " 39  x40     56050 non-null  float64\n",
            " 40  x41     56050 non-null  float64\n",
            " 41  x42     56050 non-null  float64\n",
            " 42  x43     56050 non-null  float64\n",
            " 43  x44     56050 non-null  bool   \n",
            "dtypes: bool(1), float64(27), int64(16)\n",
            "memory usage: 18.4 MB\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 51727 entries, 0 to 51726\n",
            "Data columns (total 44 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   x1      51727 non-null  float64\n",
            " 1   x2      51727 non-null  float64\n",
            " 2   x3      51727 non-null  float64\n",
            " 3   x4      51727 non-null  float64\n",
            " 4   x5      51727 non-null  float64\n",
            " 5   x6      51727 non-null  float64\n",
            " 6   x7      51727 non-null  int64  \n",
            " 7   x8      51727 non-null  int64  \n",
            " 8   x9      51727 non-null  int64  \n",
            " 9   x10     51727 non-null  int64  \n",
            " 10  x11     51727 non-null  int64  \n",
            " 11  x12     51727 non-null  int64  \n",
            " 12  x13     51727 non-null  int64  \n",
            " 13  x14     51727 non-null  int64  \n",
            " 14  x15     51727 non-null  int64  \n",
            " 15  x16     51727 non-null  int64  \n",
            " 16  x17     51727 non-null  int64  \n",
            " 17  x18     51727 non-null  int64  \n",
            " 18  x19     51727 non-null  int64  \n",
            " 19  x20     51727 non-null  float64\n",
            " 20  x21     51727 non-null  int64  \n",
            " 21  x22     51727 non-null  float64\n",
            " 22  x23     51727 non-null  float64\n",
            " 23  x24     51727 non-null  float64\n",
            " 24  x25     51727 non-null  int64  \n",
            " 25  x26     51727 non-null  int64  \n",
            " 26  x27     51727 non-null  float64\n",
            " 27  x28     51727 non-null  float64\n",
            " 28  x29     51727 non-null  float64\n",
            " 29  x30     51727 non-null  float64\n",
            " 30  x31     51727 non-null  float64\n",
            " 31  x32     51727 non-null  float64\n",
            " 32  x33     51727 non-null  float64\n",
            " 33  x34     51727 non-null  float64\n",
            " 34  x35     51727 non-null  float64\n",
            " 35  x36     51727 non-null  float64\n",
            " 36  x37     51727 non-null  float64\n",
            " 37  x38     51727 non-null  float64\n",
            " 38  x39     51727 non-null  float64\n",
            " 39  x40     51727 non-null  float64\n",
            " 40  x41     51727 non-null  float64\n",
            " 41  x42     51727 non-null  float64\n",
            " 42  x43     51727 non-null  float64\n",
            " 43  x44     51727 non-null  bool   \n",
            "dtypes: bool(1), float64(27), int64(16)\n",
            "memory usage: 17.0 MB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Load the datasets\n",
        "data1 = pd.read_csv('/content/drive/MyDrive/data1_modified.csv')\n",
        "data2 = pd.read_csv('/content/drive/MyDrive/data2_modified.csv')\n",
        "# Display dataset information\n",
        "print(data1.info())\n",
        "print(data2.info())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0K_L85Q_0q2",
        "outputId": "068fa193-5c63-4bb5-cc1a-5d6792f19b51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x44\n",
            "False    43303\n",
            "True     12747\n",
            "Name: count, dtype: int64\n",
            "x44\n",
            "False    39625\n",
            "True     12102\n",
            "Name: count, dtype: int64\n",
            "                 x1            x2            x3            x4            x5  \\\n",
            "count  56050.000000  56050.000000  56050.000000  56050.000000  56050.000000   \n",
            "mean       4.872319      2.585807     52.590935     26.868416     79.459663   \n",
            "std        3.645979      2.647797     24.269515     20.692752     16.029705   \n",
            "min        1.500000      0.250000      1.320000      0.000000      9.210000   \n",
            "25%        2.500000      1.000000     33.330000     10.000000     70.000000   \n",
            "50%        3.750000      1.750000     54.550000     23.080000     82.760000   \n",
            "75%        5.750000      3.250000     71.430000     41.180000     91.430000   \n",
            "max       83.500000     71.750000    100.000000     95.000000    100.000000   \n",
            "\n",
            "                 x6            x7            x8            x9           x10  \\\n",
            "count  56050.000000  56050.000000  56050.000000  56050.000000  56050.000000   \n",
            "mean       3.816186   -240.668029   1396.826869   -197.374023   1380.069438   \n",
            "std        3.062197    470.163131   1448.357815    539.245485   1467.615910   \n",
            "min        1.500000  -8912.000000 -14423.000000  -8777.000000 -14605.000000   \n",
            "25%        2.000000   -340.000000    485.000000   -351.000000    460.000000   \n",
            "50%        2.750000    -93.000000   1012.000000    -89.000000    995.000000   \n",
            "75%        4.500000      0.000000   1883.000000     46.000000   1878.000000   \n",
            "max       78.250000   3995.000000  18214.000000   6976.000000  19378.000000   \n",
            "\n",
            "       ...           x34           x35           x36           x37  \\\n",
            "count  ...  56050.000000  56050.000000  56050.000000  56050.000000   \n",
            "mean   ...     61.153596      9.162541     -0.027371      0.340800   \n",
            "std    ...     29.625800      6.866020      1.157304      1.173523   \n",
            "min    ...      1.970000      0.540000     -4.030000     -3.770000   \n",
            "25%    ...     34.620000      4.360000     -0.990000     -0.630000   \n",
            "50%    ...     62.640000      7.290000     -0.020000      0.400000   \n",
            "75%    ...     90.187500     11.817500      0.960000      1.320000   \n",
            "max    ...    100.000000     60.240000      3.090000      3.880000   \n",
            "\n",
            "                x38           x39           x40           x41           x42  \\\n",
            "count  56050.000000  56050.000000  56050.000000  56050.000000  56050.000000   \n",
            "mean      -0.199277      0.476867     -0.081490      2.504318     -1.311869   \n",
            "std        1.187690      1.177966     13.873159     13.826397     14.071649   \n",
            "min       -4.370000     -3.690000    -93.950000    -86.570000   -100.970000   \n",
            "25%       -1.180000     -0.500000     -6.220000     -3.970000     -7.450000   \n",
            "50%       -0.220000      0.550000     -0.120000      1.930000     -1.060000   \n",
            "75%        0.810000      1.440000      6.430000      8.880000      5.420000   \n",
            "max        2.960000      4.720000     96.530000    105.530000     91.790000   \n",
            "\n",
            "                x43  \n",
            "count  56050.000000  \n",
            "mean       3.560451  \n",
            "std       13.768823  \n",
            "min      -81.970000  \n",
            "25%       -3.090000  \n",
            "50%        2.700000  \n",
            "75%        9.827500  \n",
            "max      107.330000  \n",
            "\n",
            "[8 rows x 43 columns]\n",
            "                 x1            x2            x3            x4            x5  \\\n",
            "count  51727.000000  51727.000000  51727.000000  51727.000000  51727.000000   \n",
            "mean      21.102007     10.988072     50.960281     73.993316     23.032948   \n",
            "std       15.281594     11.298189     25.065097     20.373480     17.067657   \n",
            "min        5.000000      0.250000      0.440000      2.700000      0.000000   \n",
            "25%       10.750000      4.250000     31.195000     60.580000      9.200000   \n",
            "50%       16.750000      7.250000     52.540000     78.120000     19.510000   \n",
            "75%       26.500000     13.750000     71.250000     91.180000     33.390000   \n",
            "max      256.750000    241.250000    100.000000    100.000000     89.660000   \n",
            "\n",
            "                 x6            x7            x8            x9           x10  \\\n",
            "count  51727.000000  51727.000000  51727.000000  51727.000000  51727.000000   \n",
            "mean      16.125650   -385.155973     80.692772   -381.586638     74.838421   \n",
            "std       13.003942    339.717129    145.632545    340.565655    149.772496   \n",
            "min        5.000000  -9809.000000  -6609.000000  -9814.000000  -6609.000000   \n",
            "25%        7.500000   -530.000000      4.000000   -527.000000     -1.000000   \n",
            "50%       12.000000   -317.000000     41.000000   -314.000000     37.000000   \n",
            "75%       19.750000   -169.000000    121.000000   -165.000000    118.000000   \n",
            "max      254.000000   2134.000000   2343.000000   2135.000000   2378.000000   \n",
            "\n",
            "       ...           x34           x35           x36           x37  \\\n",
            "count  ...  51727.000000  51727.000000  51727.000000  51727.000000   \n",
            "mean   ...     56.074561     40.178315      0.055574     -0.323745   \n",
            "std    ...     29.679718     28.889170      1.160131      1.228903   \n",
            "min    ...      1.480000      1.470000     -3.130000     -4.700000   \n",
            "25%    ...     28.980000     18.490000     -0.920000     -1.320000   \n",
            "50%    ...     56.110000     33.890000      0.040000     -0.400000   \n",
            "75%    ...     84.340000     54.310000      1.050000      0.710000   \n",
            "max    ...    100.000000    214.900000      3.480000      3.240000   \n",
            "\n",
            "                x38           x39           x40           x41           x42  \\\n",
            "count  51727.000000  51727.000000  51727.000000  51727.000000  51727.000000   \n",
            "mean      -0.476736      0.221604      0.271150    -10.716922    -15.693279   \n",
            "std        1.252642      1.173001     60.458878     62.264230     62.867149   \n",
            "min       -4.740000     -2.940000   -360.540000   -436.320000   -446.820000   \n",
            "25%       -1.480000     -0.770000    -26.870000    -38.630000    -44.130000   \n",
            "50%       -0.570000      0.230000      0.790000     -7.700000    -11.160000   \n",
            "75%        0.570000      1.230000     29.140000     19.720000     15.545000   \n",
            "max        3.140000      4.130000    473.090000    470.090000    449.920000   \n",
            "\n",
            "                x43  \n",
            "count  51727.000000  \n",
            "mean       5.408728  \n",
            "std       60.274502  \n",
            "min     -355.290000  \n",
            "25%      -22.300000  \n",
            "50%        4.360000  \n",
            "75%       34.300000  \n",
            "max      490.780000  \n",
            "\n",
            "[8 rows x 43 columns]\n"
          ]
        }
      ],
      "source": [
        "# Check the target variable distribution (x44)\n",
        "print(data1['x44'].value_counts())\n",
        "print(data2['x44'].value_counts())\n",
        "\n",
        "# Describe features\n",
        "print(data1.describe())\n",
        "print(data2.describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qhoD8gxk_-YU"
      },
      "outputs": [],
      "source": [
        "# Define features (X) and target (y)\n",
        "X1 = data1.drop('x44', axis=1)\n",
        "y1 = data1['x44']\n",
        "\n",
        "X2 = data2.drop('x44', axis=1)\n",
        "y2 = data2['x44']\n",
        "\n",
        "# Train-test split (80% train, 20% test)\n",
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=0.1, shuffle=False)\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.1, shuffle=False)\n",
        "\n",
        "# Scaling features\n",
        "scaler = StandardScaler()\n",
        "X_train1_scaled = scaler.fit_transform(X_train1)\n",
        "X_test1_scaled = scaler.transform(X_test1)\n",
        "\n",
        "X_train2_scaled = scaler.fit_transform(X_train2)\n",
        "X_test2_scaled = scaler.transform(X_test2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression Model Dataset 1"
      ],
      "metadata": {
        "id": "P88VTXss-ftE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sn22bZyxAjva",
        "outputId": "08ab4e2b-7e68-4d50-c745-11cd007c35f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision for Dataset 1 (Logistic Regression): 0.4762\n"
          ]
        }
      ],
      "source": [
        "# Logistic Regression Model\n",
        "log_reg = LogisticRegression(max_iter=1000)\n",
        "log_reg.fit(X_train1_scaled, y_train1)\n",
        "y_pred1 = log_reg.predict(X_test1_scaled)\n",
        "\n",
        "# Precision score\n",
        "# Changed 'True' to True\n",
        "precision1 = precision_score(y_test1, y_pred1, pos_label=True)\n",
        "print(f\"Precision for Dataset 1 (Logistic Regression): {precision1:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest Model for Dataset 2"
      ],
      "metadata": {
        "id": "xKZXdttr_qSc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import precision_score\n",
        "\n",
        "# Random Forest Model for Dataset 2\n",
        "rf2 = RandomForestClassifier(class_weight='balanced', n_estimators=100, random_state=42)\n",
        "rf2.fit(X_train2_scaled, y_train2)\n",
        "y_pred2_rf = rf2.predict(X_test2_scaled)\n",
        "\n",
        "# Precision score for Dataset 2\n",
        "precision2_rf = precision_score(y_test2, y_pred2_rf, pos_label=True)\n",
        "print(f\"Precision for Dataset 2 (Random Forest): {precision2_rf:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QO3PPR_vG3RH",
        "outputId": "1cf85615-1d13-4767-c3b3-3bc0d7eaabbd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision for Dataset 2 (Random Forest): 0.5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "# XGBoost Model for Dataset 1\n",
        "xgb1 = xgb.XGBClassifier(scale_pos_weight=(len(y_train1) / sum(y_train1 == True)), use_label_encoder=False, eval_metric='logloss')\n",
        "xgb1.fit(X_train1_scaled, y_train1)\n",
        "y_pred1_xgb = xgb1.predict(X_test1_scaled)\n",
        "\n",
        "# Precision score for Dataset 1\n",
        "precision1_xgb = precision_score(y_test1, y_pred1_xgb, pos_label=True)\n",
        "print(f\"Precision for Dataset 1 (XGBoost): {precision1_xgb:.4f}\")\n",
        "\n",
        "# XGBoost Model for Dataset 2\n",
        "xgb2 = xgb.XGBClassifier(scale_pos_weight=(len(y_train2) / sum(y_train2 == True)), use_label_encoder=False, eval_metric='logloss')\n",
        "xgb2.fit(X_train2_scaled, y_train2)\n",
        "y_pred2_xgb = xgb2.predict(X_test2_scaled)\n",
        "\n",
        "# Precision score for Dataset 2\n",
        "precision2_xgb = precision_score(y_test2, y_pred2_xgb, pos_label=True)\n",
        "print(f\"Precision for Dataset 2 (XGBoost): {precision2_xgb:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtHU-TeJLaOw",
        "outputId": "7fb0ef19-49b9-488d-aa33-9f76a0f1030b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [17:04:49] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision for Dataset 1 (XGBoost): 0.2442\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [17:04:54] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision for Dataset 2 (XGBoost): 0.2352\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# SVM Model for Dataset 1\n",
        "svm1 = SVC(kernel='rbf', class_weight='balanced', random_state=42)\n",
        "svm1.fit(X_train1_scaled, y_train1)\n",
        "y_pred1_svm = svm1.predict(X_test1_scaled)\n",
        "\n",
        "# Precision score for Dataset 1\n",
        "precision1_svm = precision_score(y_test1, y_pred1_svm, pos_label=True)\n",
        "print(f\"Precision for Dataset 1 (SVM): {precision1_svm:.4f}\")\n",
        "\n",
        "# SVM Model for Dataset 2\n",
        "svm2 = SVC(kernel='rbf', class_weight='balanced', random_state=42)\n",
        "svm2.fit(X_train2_scaled, y_train2)\n",
        "y_pred2_svm = svm2.predict(X_test2_scaled)\n",
        "\n",
        "# Precision score for Dataset 2\n",
        "precision2_svm = precision_score(y_test2, y_pred2_svm, pos_label=True)\n",
        "print(f\"Precision for Dataset 2 (SVM): {precision2_svm:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-kt5F2VMAQn",
        "outputId": "adca0ced-3b04-4924-9e71-c10d6e92412a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision for Dataset 1 (SVM): 0.2452\n",
            "Precision for Dataset 2 (SVM): 0.2353\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Gradient Boosting Model for Dataset 1"
      ],
      "metadata": {
        "id": "XOPnxikp_-gb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# Gradient Boosting Model for Dataset 1\n",
        "gbm1 = GradientBoostingClassifier(random_state=42)\n",
        "gbm1.fit(X_train1_scaled, y_train1)\n",
        "y_pred1_gbm = gbm1.predict(X_test1_scaled)\n",
        "\n",
        "# Precision score for Dataset 1\n",
        "precision1_gbm = precision_score(y_test1, y_pred1_gbm, pos_label=True)\n",
        "print(f\"Precision for Dataset 1 (Gradient Boosting): {precision1_gbm:.4f}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUhBSur5R6ej",
        "outputId": "137d5594-8401-413e-bde6-6591a51eded8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision for Dataset 1 (Gradient Boosting): 0.5556\n",
            "Precision for Dataset 2 (Gradient Boosting): 0.2250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradient Boosting Model for Dataset 2\n",
        "gbm2 = GradientBoostingClassifier(random_state=101)\n",
        "gbm2.fit(X_train2_scaled, y_train2)\n",
        "y_pred2_gbm = gbm2.predict(X_test2_scaled)\n",
        "\n",
        "# Precision score for Dataset 2\n",
        "precision2_gbm = precision_score(y_test2, y_pred2_gbm, pos_label=True)\n",
        "print(f\"Precision for Dataset 2 (Gradient Boosting): {precision2_gbm:.4f}\")"
      ],
      "metadata": {
        "id": "kQ-iOqIL-WKK",
        "outputId": "50340969-de92-4868-eb6e-7e535de3151a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision for Dataset 2 (Gradient Boosting): 0.2368\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.metrics import precision_score\n",
        "import numpy as np\n",
        "\n",
        "# ANN Model for Dataset 1\n",
        "ann1 = Sequential()\n",
        "ann1.add(Dense(64, input_dim=X_train1_scaled.shape[1], activation='relu'))\n",
        "ann1.add(Dense(32, activation='relu'))\n",
        "ann1.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "ann1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['Precision'])\n",
        "\n",
        "# Train the model for Dataset 1\n",
        "ann1.fit(X_train1_scaled, y_train1, epochs=20, batch_size=64, verbose=1)\n",
        "\n",
        "# Predictions for Dataset 1\n",
        "y_pred1_ann = (ann1.predict(X_test1_scaled) > 0.5).astype(int)\n",
        "\n",
        "# Precision score for Dataset 1\n",
        "precision1_ann = precision_score(y_test1, y_pred1_ann)\n",
        "print(f\"Precision for Dataset 1 (ANN): {precision1_ann:.4f}\")\n",
        "\n",
        "# ANN Model for Dataset 2\n",
        "ann2 = Sequential()\n",
        "ann2.add(Dense(64, input_dim=X_train2_scaled.shape[1], activation='relu'))\n",
        "ann2.add(Dense(32, activation='relu'))\n",
        "ann2.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "ann2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['Precision'])\n",
        "\n",
        "# Train the model for Dataset 2\n",
        "ann2.fit(X_train2_scaled, y_train2, epochs=20, batch_size=64, verbose=1)\n",
        "\n",
        "# Predictions for Dataset 2\n",
        "y_pred2_ann = (ann2.predict(X_test2_scaled) > 0.5).astype(int)\n",
        "\n",
        "# Precision score for Dataset 2\n",
        "precision2_ann = precision_score(y_test2, y_pred2_ann)\n",
        "print(f\"Precision for Dataset 2 (ANN): {precision2_ann:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkK8O2uVSCDO",
        "outputId": "df5836c5-30b1-4c6d-eeb6-c944ac086251"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - Precision: 0.2001 - loss: 0.5472\n",
            "Epoch 2/20\n",
            "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - Precision: 0.1731 - loss: 0.5277\n",
            "Epoch 3/20\n",
            "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - Precision: 0.1276 - loss: 0.5291\n",
            "Epoch 4/20\n",
            "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - Precision: 0.5181 - loss: 0.5293\n",
            "Epoch 5/20\n",
            "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - Precision: 0.2426 - loss: 0.5312\n",
            "Epoch 6/20\n",
            "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Precision: 0.2091 - loss: 0.5261\n",
            "Epoch 7/20\n",
            "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.5497 - loss: 0.5239\n",
            "Epoch 8/20\n",
            "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - Precision: 0.6607 - loss: 0.5233\n",
            "Epoch 9/20\n",
            "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - Precision: 0.5948 - loss: 0.5282\n",
            "Epoch 10/20\n",
            "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - Precision: 0.7243 - loss: 0.5251\n",
            "Epoch 11/20\n",
            "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - Precision: 0.5450 - loss: 0.5221\n",
            "Epoch 12/20\n",
            "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - Precision: 0.6320 - loss: 0.5192\n",
            "Epoch 13/20\n",
            "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - Precision: 0.5887 - loss: 0.5217\n",
            "Epoch 14/20\n",
            "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - Precision: 0.5996 - loss: 0.5194\n",
            "Epoch 15/20\n",
            "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - Precision: 0.6254 - loss: 0.5174\n",
            "Epoch 16/20\n",
            "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - Precision: 0.6366 - loss: 0.5205\n",
            "Epoch 17/20\n",
            "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.7018 - loss: 0.5192\n",
            "Epoch 18/20\n",
            "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.5489 - loss: 0.5129\n",
            "Epoch 19/20\n",
            "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - Precision: 0.6361 - loss: 0.5125\n",
            "Epoch 20/20\n",
            "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - Precision: 0.6451 - loss: 0.5163\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "Precision for Dataset 1 (ANN): 0.1607\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m647/647\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - Precision: 0.2474 - loss: 0.5760\n",
            "Epoch 2/20\n",
            "\u001b[1m647/647\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - Precision: 0.0000e+00 - loss: 0.5553\n",
            "Epoch 3/20\n",
            "\u001b[1m647/647\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - Precision: 0.3719 - loss: 0.5432\n",
            "Epoch 4/20\n",
            "\u001b[1m647/647\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - Precision: 0.1879 - loss: 0.5456\n",
            "Epoch 5/20\n",
            "\u001b[1m647/647\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.0000e+00 - loss: 0.5436\n",
            "Epoch 6/20\n",
            "\u001b[1m647/647\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.0216 - loss: 0.5422\n",
            "Epoch 7/20\n",
            "\u001b[1m647/647\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - Precision: 0.2238 - loss: 0.5412\n",
            "Epoch 8/20\n",
            "\u001b[1m647/647\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - Precision: 0.5495 - loss: 0.5448\n",
            "Epoch 9/20\n",
            "\u001b[1m647/647\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - Precision: 0.3891 - loss: 0.5399\n",
            "Epoch 10/20\n",
            "\u001b[1m647/647\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - Precision: 0.5474 - loss: 0.5393\n",
            "Epoch 11/20\n",
            "\u001b[1m647/647\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - Precision: 0.6454 - loss: 0.5396\n",
            "Epoch 12/20\n",
            "\u001b[1m647/647\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - Precision: 0.7543 - loss: 0.5396\n",
            "Epoch 13/20\n",
            "\u001b[1m647/647\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - Precision: 0.4824 - loss: 0.5404\n",
            "Epoch 14/20\n",
            "\u001b[1m647/647\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.5318 - loss: 0.5382\n",
            "Epoch 15/20\n",
            "\u001b[1m647/647\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.5970 - loss: 0.5367\n",
            "Epoch 16/20\n",
            "\u001b[1m647/647\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - Precision: 0.5730 - loss: 0.5397\n",
            "Epoch 17/20\n",
            "\u001b[1m647/647\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - Precision: 0.6145 - loss: 0.5363\n",
            "Epoch 18/20\n",
            "\u001b[1m647/647\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - Precision: 0.6371 - loss: 0.5359\n",
            "Epoch 19/20\n",
            "\u001b[1m647/647\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - Precision: 0.6015 - loss: 0.5354\n",
            "Epoch 20/20\n",
            "\u001b[1m647/647\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - Precision: 0.6054 - loss: 0.5328\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "Precision for Dataset 2 (ANN): 0.2500\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/awaiskhan005/DATA-SCIENCE-AND-AI-/blob/main/iSREAL_PROJECT_2ND.ipynb",
      "authorship_tag": "ABX9TyOzhPfYHuXnMil/AyaPsYid",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}