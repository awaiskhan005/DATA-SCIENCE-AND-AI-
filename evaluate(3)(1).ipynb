{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/awaiskhan005/DATA-SCIENCE-AND-AI-/blob/main/evaluate(3)(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aK0_jKjoBZkr",
        "outputId": "c214d06a-4a4c-464e-b57f-2d376408b0e9"
      },
      "id": "aK0_jKjoBZkr",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama_index\n",
            "  Downloading llama_index-0.10.33-py3-none-any.whl (6.9 kB)\n",
            "Collecting llama-index-agent-openai<0.3.0,>=0.1.4 (from llama_index)\n",
            "  Downloading llama_index_agent_openai-0.2.3-py3-none-any.whl (13 kB)\n",
            "Collecting llama-index-cli<0.2.0,>=0.1.2 (from llama_index)\n",
            "  Downloading llama_index_cli-0.1.12-py3-none-any.whl (26 kB)\n",
            "Collecting llama-index-core<0.11.0,>=0.10.32 (from llama_index)\n",
            "  Downloading llama_index_core-0.10.33-py3-none-any.whl (15.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-index-embeddings-openai<0.2.0,>=0.1.5 (from llama_index)\n",
            "  Downloading llama_index_embeddings_openai-0.1.9-py3-none-any.whl (6.0 kB)\n",
            "Collecting llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 (from llama_index)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.1.6-py3-none-any.whl (6.7 kB)\n",
            "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama_index)\n",
            "  Downloading llama_index_legacy-0.9.48-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-index-llms-openai<0.2.0,>=0.1.13 (from llama_index)\n",
            "  Downloading llama_index_llms_openai-0.1.16-py3-none-any.whl (10 kB)\n",
            "Collecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 (from llama_index)\n",
            "  Downloading llama_index_multi_modal_llms_openai-0.1.5-py3-none-any.whl (5.8 kB)\n",
            "Collecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama_index)\n",
            "  Downloading llama_index_program_openai-0.1.6-py3-none-any.whl (5.2 kB)\n",
            "Collecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama_index)\n",
            "  Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\n",
            "Collecting llama-index-readers-file<0.2.0,>=0.1.4 (from llama_index)\n",
            "  Downloading llama_index_readers_file-0.1.19-py3-none-any.whl (36 kB)\n",
            "Collecting llama-index-readers-llama-parse<0.2.0,>=0.1.2 (from llama_index)\n",
            "  Downloading llama_index_readers_llama_parse-0.1.4-py3-none-any.whl (2.5 kB)\n",
            "Collecting openai>=1.14.0 (from llama-index-agent-openai<0.3.0,>=0.1.4->llama_index)\n",
            "  Downloading openai-1.24.0-py3-none-any.whl (312 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.3/312.3 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.32->llama_index) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.32->llama_index) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.32->llama_index) (3.9.5)\n",
            "Collecting dataclasses-json (from llama-index-core<0.11.0,>=0.10.32->llama_index)\n",
            "  Downloading dataclasses_json-0.6.5-py3-none-any.whl (28 kB)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.11.0,>=0.10.32->llama_index)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.11.0,>=0.10.32->llama_index)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.32->llama_index) (2023.6.0)\n",
            "Collecting httpx (from llama-index-core<0.11.0,>=0.10.32->llama_index)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llamaindex-py-client<0.2.0,>=0.1.18 (from llama-index-core<0.11.0,>=0.10.32->llama_index)\n",
            "  Downloading llamaindex_py_client-0.1.19-py3-none-any.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.32->llama_index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.32->llama_index) (3.3)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.32->llama_index) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.32->llama_index) (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.32->llama_index) (2.0.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.32->llama_index) (9.4.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.32->llama_index) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.32->llama_index) (8.2.3)\n",
            "Collecting tiktoken>=0.3.3 (from llama-index-core<0.11.0,>=0.10.32->llama_index)\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.32->llama_index) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.32->llama_index) (4.11.0)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.11.0,>=0.10.32->llama_index)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.32->llama_index) (1.14.1)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama_index) (4.12.3)\n",
            "Collecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.2.0,>=0.1.4->llama_index)\n",
            "  Downloading pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.2.0,>=0.1.4->llama_index)\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Collecting llama-parse<0.5.0,>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index)\n",
            "  Downloading llama_parse-0.4.2-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.32->llama_index) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.32->llama_index) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.32->llama_index) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.32->llama_index) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.32->llama_index) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.32->llama_index) (4.0.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama_index) (2.5)\n",
            "Requirement already satisfied: pydantic>=1.10 in /usr/local/lib/python3.10/dist-packages (from llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.32->llama_index) (2.7.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.32->llama_index) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.32->llama_index) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx->llama-index-core<0.11.0,>=0.10.32->llama_index)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.32->llama_index) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.32->llama_index) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.32->llama_index)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.32->llama_index) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.32->llama_index) (1.4.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.32->llama_index) (2023.12.25)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.3.0,>=0.1.4->llama_index) (1.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.32->llama_index) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.32->llama_index) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.32->llama_index) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.32->llama_index)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.11.0,>=0.10.32->llama_index)\n",
            "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.32->llama_index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.32->llama_index) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.32->llama_index) (2024.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.32->llama_index) (1.2.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.32->llama_index) (24.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.32->llama_index) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.32->llama_index) (2.18.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.32->llama_index) (1.16.0)\n",
            "Installing collected packages: striprtf, dirtyjson, pypdf, mypy-extensions, marshmallow, h11, deprecated, typing-inspect, tiktoken, httpcore, httpx, dataclasses-json, openai, llamaindex-py-client, llama-index-legacy, llama-index-core, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama_index\n",
            "Successfully installed dataclasses-json-0.6.5 deprecated-1.2.14 dirtyjson-1.0.8 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 llama-index-agent-openai-0.2.3 llama-index-cli-0.1.12 llama-index-core-0.10.33 llama-index-embeddings-openai-0.1.9 llama-index-indices-managed-llama-cloud-0.1.6 llama-index-legacy-0.9.48 llama-index-llms-openai-0.1.16 llama-index-multi-modal-llms-openai-0.1.5 llama-index-program-openai-0.1.6 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.19 llama-index-readers-llama-parse-0.1.4 llama-parse-0.4.2 llama_index-0.10.33 llamaindex-py-client-0.1.19 marshmallow-3.21.1 mypy-extensions-1.0.0 openai-1.24.0 pypdf-4.2.0 striprtf-0.0.26 tiktoken-0.6.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "initial_id",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-22T08:05:43.875359Z",
          "start_time": "2024-04-22T08:05:40.498231Z"
        },
        "collapsed": true,
        "id": "initial_id"
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "from llama_index.core.evaluation import generate_question_context_pairs\n",
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n",
        "from llama_index.core.node_parser import SimpleNodeParser\n",
        "from llama_index.core.evaluation import generate_question_context_pairs\n",
        "from llama_index.core.evaluation import RetrieverEvaluator\n",
        "from  llama_index.embeddings.openai import OpenAIEmbedding\n",
        "from llama_index.llms.openai import OpenAI\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] =''\n",
        "os.environ['OPENAI_API_BASE']=\"https://api.xty.app/v1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1dc1f66e1ad33627",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-22T08:05:47.724463Z",
          "start_time": "2024-04-22T08:05:47.554844Z"
        },
        "id": "1dc1f66e1ad33627"
      },
      "outputs": [],
      "source": [
        "documents = SimpleDirectoryReader(\"/home/user3/Base_model/Qwen/NSFc\").load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cd8e38a7f21954",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-22T08:06:31.568536Z",
          "start_time": "2024-04-22T08:06:31.565986Z"
        },
        "id": "6cd8e38a7f21954"
      },
      "outputs": [],
      "source": [
        "llm = OpenAI(model=\"gpt-4\",temperature=0.7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e0af7925a6748a2",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-22T08:06:36.249886Z",
          "start_time": "2024-04-22T08:06:33.259074Z"
        },
        "id": "9e0af7925a6748a2"
      },
      "outputs": [],
      "source": [
        "node_parser = SimpleNodeParser.from_defaults(chunk_size=512)\n",
        "nodes = node_parser.get_nodes_from_documents(documents)\n",
        "vector_index = VectorStoreIndex(nodes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ccb874b08b6d3835",
      "metadata": {
        "id": "ccb874b08b6d3835"
      },
      "source": [
        "## 重新生成问题"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fe3904f0ec1225d",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-22T08:08:08.985117Z",
          "start_time": "2024-04-22T08:06:43.649001Z"
        },
        "id": "9fe3904f0ec1225d",
        "outputId": "71ff9b7d-1991-4fa6-c936-9bdb9d043373"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [06:12<00:00,  2.91s/it]\n"
          ]
        }
      ],
      "source": [
        "qa_generate_prompt_tmpl = \"\"\"\\\n",
        "上下文信息如下所示：\n",
        "\n",
        "---------------------\n",
        "{context_str}\n",
        "---------------------\n",
        "\n",
        "给定上下文信息而非先验知识。\n",
        "仅根据以下查询生成问题。\n",
        "\n",
        "你是申请国家自然科学基金的研究人员。你的任务是为即将到来的中文测验设置{num_questions_per_chunk}个问题。\n",
        "整个测试中的问题应该多种多样,问题不应包含选项,必须用中文书写。表达必须简明扼要。也就是说当你作为申请人的时候你最想根据你自己的项目问这上面的内容什么问题。\n",
        "不应超过25个汉字。诸如\"根据\", \"依据\",\"你\"和其他标点符号不应使用。缩写可用于标题和专业术语。\n",
        "\"\"\"\n",
        "test_dataset = generate_question_context_pairs(\n",
        "    nodes[:],\n",
        "    llm=llm,\n",
        "    num_questions_per_chunk=1,\n",
        "    qa_generate_prompt_tmpl=qa_generate_prompt_tmpl\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed828dab88b84441",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-22T08:09:01.590211Z",
          "start_time": "2024-04-22T08:09:01.587575Z"
        },
        "id": "ed828dab88b84441",
        "outputId": "bc0fceab-0712-4e22-eeb9-ac394ea684dd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No sentence-transformers model found with name google-bert/bert-base-chinese. Creating a new one with MEAN pooling.\n",
            "/home/user3/.conda/envs/RAG/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/home/user3/.conda/envs/RAG/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core.embeddings import resolve_embed_model\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "\n",
        "\n",
        "EMBEDDINGS = {\n",
        "    \"OpenAI\": OpenAIEmbedding(),\n",
        "    \"Bert\": HuggingFaceEmbedding(model_name=\"google-bert/bert-base-chinese\"),\n",
        "    \"Bge-zh\": HuggingFaceEmbedding(model_name='BAAI/bge-large-zh-v1.5', trust_remote_code=True),\n",
        "    \"finetuned-Bge\" : resolve_embed_model(\"local:/home/user3/Base_model/Qwen/bge-retrieve-Finetuning_Model\"),\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "209fe62bec286d8c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-22T08:09:09.357625Z",
          "start_time": "2024-04-22T08:09:09.355207Z"
        },
        "id": "209fe62bec286d8c"
      },
      "outputs": [],
      "source": [
        "\n",
        "from llama_index.core.postprocessor import SentenceTransformerRerank\n",
        "RERANKERS = {\n",
        "    \"WithoutReranker\": \"None\",\n",
        "    \"bge-reranker-base\": SentenceTransformerRerank(model=\"BAAI/bge-reranker-base\", top_n=5),\n",
        "    \"bge-reranker-large\": SentenceTransformerRerank(model=\"BAAI/bge-reranker-large\", top_n=5),\n",
        "    \"finetuned-Bge-reranker\" : SentenceTransformerRerank(model=\"/home/user3/Base_model/Qwen/bge-rerank-Finetuning_Model1\",top_n=5),\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6227c24a495370b2",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-08T03:41:59.174876Z",
          "start_time": "2024-04-08T03:41:59.171457Z"
        },
        "id": "6227c24a495370b2"
      },
      "outputs": [],
      "source": [
        "def display_results(embedding_name, reranker_name, eval_results):\n",
        "    \"\"\"Display results from evaluate.\"\"\"\n",
        "\n",
        "    metric_dicts = []\n",
        "    for eval_result in eval_results:\n",
        "        metric_dict = eval_result.metric_vals_dict\n",
        "        metric_dicts.append(metric_dict)\n",
        "\n",
        "    full_df = pd.DataFrame(metric_dicts)\n",
        "\n",
        "    hit_rate = full_df[\"hit_rate\"].mean()\n",
        "    mrr = full_df[\"mrr\"].mean()\n",
        "\n",
        "    metric_df = pd.DataFrame(\n",
        "        {\"Embedding\": [embedding_name], \"Reranker\": [reranker_name], \"hit_rate\": [hit_rate], \"mrr\": [mrr]}\n",
        "    )\n",
        "\n",
        "    return metric_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40991700184e1867",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-08T02:12:38.088646Z",
          "start_time": "2024-04-08T02:11:46.151002Z"
        },
        "id": "40991700184e1867",
        "outputId": "8cb4cec6-9d4c-4be5-95b2-22124b0000f7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1708168/2359604037.py:14: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
            "  service_context = ServiceContext.from_defaults(llm=None, embed_model=embed_model)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LLM is explicitly disabled. Using MockLLM.\n",
            "Running Evaluation for Embedding Model: OpenAI and Reranker: WithoutReranker\n",
            "Running Evaluation for Embedding Model: OpenAI and Reranker: bge-reranker-base\n",
            "Running Evaluation for Embedding Model: OpenAI and Reranker: bge-reranker-large\n",
            "Running Evaluation for Embedding Model: OpenAI and Reranker: finetuned-Bge-reranker\n",
            "LLM is explicitly disabled. Using MockLLM.\n",
            "Running Evaluation for Embedding Model: Bert and Reranker: WithoutReranker\n",
            "Running Evaluation for Embedding Model: Bert and Reranker: bge-reranker-base\n",
            "Running Evaluation for Embedding Model: Bert and Reranker: bge-reranker-large\n",
            "Running Evaluation for Embedding Model: Bert and Reranker: finetuned-Bge-reranker\n",
            "LLM is explicitly disabled. Using MockLLM.\n",
            "Running Evaluation for Embedding Model: Bge-zh and Reranker: WithoutReranker\n",
            "Running Evaluation for Embedding Model: Bge-zh and Reranker: bge-reranker-base\n",
            "Running Evaluation for Embedding Model: Bge-zh and Reranker: bge-reranker-large\n",
            "Running Evaluation for Embedding Model: Bge-zh and Reranker: finetuned-Bge-reranker\n",
            "LLM is explicitly disabled. Using MockLLM.\n",
            "Running Evaluation for Embedding Model: finetuned-Bge and Reranker: WithoutReranker\n",
            "Running Evaluation for Embedding Model: finetuned-Bge and Reranker: bge-reranker-base\n",
            "Running Evaluation for Embedding Model: finetuned-Bge and Reranker: bge-reranker-large\n",
            "Running Evaluation for Embedding Model: finetuned-Bge and Reranker: finetuned-Bge-reranker\n"
          ]
        }
      ],
      "source": [
        "# 评估mrr和hit\n",
        "from llama_index.core.indices.query.schema import QueryBundle, QueryType\n",
        "from typing import List\n",
        "from llama_index.core.schema import NodeWithScore\n",
        "results_df = pd.DataFrame()\n",
        "from llama_index.core.retrievers import (\n",
        "    BaseRetriever,\n",
        "    VectorIndexRetriever,\n",
        ")\n",
        "\n",
        "# Loop over embeddings\n",
        "for embed_name, embed_model in EMBEDDINGS.items():\n",
        "\n",
        "    service_context = ServiceContext.from_defaults(llm=None, embed_model=embed_model)\n",
        "    vector_index = VectorStoreIndex(nodes, service_context=service_context)\n",
        "    vector_retriever = VectorIndexRetriever(index=vector_index, similarity_top_k = 10)\n",
        "\n",
        "\n",
        "    # Loop over rerankers\n",
        "    for rerank_name, reranker in RERANKERS.items():\n",
        "\n",
        "        print(f\"Running Evaluation for Embedding Model: {embed_name} and Reranker: {rerank_name}\")\n",
        "\n",
        "        # Define Retriever\n",
        "        class CustomRetriever(BaseRetriever):\n",
        "            \"\"\"Custom retriever that performs both Vector search and Knowledge Graph search\"\"\"\n",
        "\n",
        "            def __init__(\n",
        "                self,\n",
        "                vector_retriever: VectorIndexRetriever,\n",
        "            ) -> None:\n",
        "                \"\"\"Init params.\"\"\"\n",
        "\n",
        "                self._vector_retriever = vector_retriever\n",
        "\n",
        "            def _retrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]:\n",
        "                \"\"\"Retrieve nodes given query.\"\"\"\n",
        "\n",
        "                retrieved_nodes = self._vector_retriever.retrieve(query_bundle)\n",
        "\n",
        "                if reranker != 'None':\n",
        "                    retrieved_nodes = reranker.postprocess_nodes(retrieved_nodes, query_bundle)\n",
        "                else:\n",
        "                    retrieved_nodes = retrieved_nodes[:5]\n",
        "\n",
        "                return retrieved_nodes\n",
        "\n",
        "            async def _aretrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]:\n",
        "                \"\"\"Asynchronously retrieve nodes given query.\n",
        "\n",
        "                Implemented by the user.\n",
        "\n",
        "                \"\"\"\n",
        "                return self._retrieve(query_bundle)\n",
        "\n",
        "            async def aretrieve(self, str_or_query_bundle: QueryType) -> List[NodeWithScore]:\n",
        "                if isinstance(str_or_query_bundle, str):\n",
        "                    str_or_query_bundle = QueryBundle(str_or_query_bundle)\n",
        "                return await self._aretrieve(str_or_query_bundle)\n",
        "\n",
        "        custom_retriever = CustomRetriever(vector_retriever)\n",
        "\n",
        "        retriever_evaluator = RetrieverEvaluator.from_metric_names(\n",
        "            [\"mrr\", \"hit_rate\"], retriever=custom_retriever\n",
        "        )\n",
        "\n",
        "        eval_results = await retriever_evaluator.aevaluate_dataset(test_dataset)\n",
        "\n",
        "        current_df = display_results(embed_name, rerank_name, eval_results)\n",
        "        results_df = pd.concat([results_df, current_df], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e89dfb5e8b0e6c67",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-07T16:03:58.795432Z",
          "start_time": "2024-04-07T16:03:58.791825Z"
        },
        "id": "e89dfb5e8b0e6c67",
        "outputId": "0cacfe6c-8a4e-41e0-d59e-53bfe2b67b94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        Embedding                Reranker  hit_rate       mrr\n",
            "0          OpenAI         WithoutReranker  0.757812  0.584896\n",
            "1          OpenAI       bge-reranker-base  0.859375  0.682161\n",
            "2          OpenAI      bge-reranker-large  0.875000  0.735156\n",
            "3          OpenAI  finetuned-Bge-reranker  0.875000  0.717578\n",
            "4            Bert         WithoutReranker  0.578125  0.394401\n",
            "5            Bert       bge-reranker-base  0.703125  0.601172\n",
            "6            Bert      bge-reranker-large  0.710938  0.633073\n",
            "7            Bert  finetuned-Bge-reranker  0.703125  0.604036\n",
            "8          Bge-zh         WithoutReranker  0.734375  0.530208\n",
            "9          Bge-zh       bge-reranker-base  0.812500  0.667188\n",
            "10         Bge-zh      bge-reranker-large  0.828125  0.717969\n",
            "11         Bge-zh  finetuned-Bge-reranker  0.843750  0.680859\n",
            "12  finetuned-Bge         WithoutReranker  0.851562  0.655599\n",
            "13  finetuned-Bge       bge-reranker-base  0.882812  0.717578\n",
            "14  finetuned-Bge      bge-reranker-large  0.914062  0.760547\n",
            "15  finetuned-Bge  finetuned-Bge-reranker  0.914062  0.721615\n"
          ]
        }
      ],
      "source": [
        "print(results_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94f54d28",
      "metadata": {
        "id": "94f54d28"
      },
      "outputs": [],
      "source": [
        "results_df.to_csv('benchmark-final.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1cc4fe9610f3ae2",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-22T08:32:59.796830Z",
          "start_time": "2024-04-22T08:32:36.490644Z"
        },
        "id": "e1cc4fe9610f3ae2"
      },
      "outputs": [],
      "source": [
        "%%capture captured_output_ContextualRelevancy\n",
        "## 评估AnswerRelevancy Faithfulness ContextualRelevancy\n",
        "import pandas as pd\n",
        "\n",
        "# 创建包含结果的DataFrame\n",
        "results_df_ContextualRelevancy = pd.DataFrame(columns=[\"Embedding Model\", \"Rerank Model\", \"Average Contextual Relevancy Score\"])\n",
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "from llama_index.core.indices.query.schema import QueryBundle, QueryType\n",
        "from typing import List\n",
        "from llama_index.core.schema import NodeWithScore\n",
        "from llama_index.core.retrievers import (\n",
        "    BaseRetriever,\n",
        "    VectorIndexRetriever,\n",
        ")\n",
        "from llama_index.core.query_engine import RetrieverQueryEngine\n",
        "\n",
        "from deepeval.integrations.llama_index import DeepEvalAnswerRelevancyEvaluator\n",
        "from deepeval.integrations.llama_index import DeepEvalFaithfulnessEvaluator\n",
        "from deepeval.integrations.llama_index import DeepEvalContextualRelevancyEvaluator\n",
        "\n",
        "# Loop over embeddings\n",
        "for embed_name, embed_model in EMBEDDINGS.items():\n",
        "\n",
        "    service_context = ServiceContext.from_defaults(llm=None, embed_model=embed_model)\n",
        "    vector_index = VectorStoreIndex(nodes, service_context=service_context)\n",
        "    vector_retriever = VectorIndexRetriever(index=vector_index, similarity_top_k = 10)\n",
        "\n",
        "\n",
        "    # Loop over rerankers\n",
        "    for rerank_name, reranker in RERANKERS.items():\n",
        "\n",
        "        print(f\"Running Evaluation for Embedding Model: {embed_name} and Reranker: {rerank_name}\")\n",
        "\n",
        "        # Define Retriever\n",
        "        class CustomRetriever(BaseRetriever):\n",
        "            \"\"\"Custom retriever that performs both Vector search and Knowledge Graph search\"\"\"\n",
        "\n",
        "            def __init__(\n",
        "                self,\n",
        "                vector_retriever: VectorIndexRetriever,\n",
        "            ) -> None:\n",
        "                \"\"\"Init params.\"\"\"\n",
        "                self._vector_retriever = vector_retriever\n",
        "\n",
        "            def _retrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]:\n",
        "                \"\"\"Retrieve nodes given query.\"\"\"\n",
        "                retrieved_nodes = self._vector_retriever.retrieve(query_bundle)\n",
        "                if reranker != 'None':\n",
        "                    retrieved_nodes = reranker.postprocess_nodes(retrieved_nodes, query_bundle)\n",
        "                else:\n",
        "                    retrieved_nodes = retrieved_nodes[:5]\n",
        "                return retrieved_nodes\n",
        "\n",
        "            async def _aretrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]:\n",
        "                return self._retrieve(query_bundle)\n",
        "            async def aretrieve(self, str_or_query_bundle: QueryType) -> List[NodeWithScore]:\n",
        "                if isinstance(str_or_query_bundle, str):\n",
        "                    str_or_query_bundle = QueryBundle(str_or_query_bundle)\n",
        "                return self._aretrieve(str_or_query_bundle)\n",
        "\n",
        "        custom_retriever = CustomRetriever(vector_retriever)\n",
        "        query_engine = RetrieverQueryEngine.from_args(custom_retriever)\n",
        "        # query_engine = custom_retriever.as_query_engine()\n",
        "        queries_list = list(test_dataset.queries.values())\n",
        "\n",
        "        contextual_relevancy_scores = []\n",
        "\n",
        "        for query in queries_list:\n",
        "            response_object =query_engine.query(query)\n",
        "            contextual_relevancy_evaluator = DeepEvalContextualRelevancyEvaluator(\n",
        "            threshold=0.5,\n",
        "            model=\"gpt-4\",\n",
        "            include_reason=False)\n",
        "\n",
        "\n",
        "            evaluation_result_contextual_relevancy = contextual_relevancy_evaluator.evaluate_response(\n",
        "                query=query,\n",
        "                response=response_object\n",
        "            )\n",
        "\n",
        "            contextual_relevancy_scores.append(evaluation_result_contextual_relevancy.score)\n",
        "        # Calculate averages\n",
        "\n",
        "        average_contextual_relevancy_score = sum(contextual_relevancy_scores) / len(contextual_relevancy_scores)\n",
        "\n",
        "        current_df = pd.DataFrame({\"Embedding Model\": embed_name, \"Rerank Model\": rerank_name, \"AverageContextualRelevancy_Score\": average_contextual_relevancy_score}, index=[0])\n",
        "        results_df_ContextualRelevancy  = pd.concat([results_df_ContextualRelevancy , current_df], ignore_index=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef71946388c1a971",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-22T08:31:27.792747Z",
          "start_time": "2024-04-22T08:31:27.790138Z"
        },
        "id": "ef71946388c1a971",
        "outputId": "2040bd2c-fb8e-4c42-ae19-37b64ae1a741"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Embedding Model            Rerank Model Average Contextual Relevancy Score  \\\n",
            "0          Bge-zh         WithoutReranker                                NaN   \n",
            "1          Bge-zh       bge-reranker-base                                NaN   \n",
            "2          Bge-zh      bge-reranker-large                                NaN   \n",
            "3          Bge-zh  finetuned-Bge-reranker                                NaN   \n",
            "\n",
            "   AverageContextualRelevancy_Score  \n",
            "0                          0.777778  \n",
            "1                          0.666667  \n",
            "2                          0.777778  \n",
            "3                          0.777778  \n"
          ]
        }
      ],
      "source": [
        "print(results_df_ContextualRelevancy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8b1af30",
      "metadata": {
        "id": "a8b1af30"
      },
      "outputs": [],
      "source": [
        "results_df_ContextualRelevancy.to_csv('ContextualRelevancy.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbd96f1344d301da",
      "metadata": {
        "id": "bbd96f1344d301da"
      },
      "outputs": [],
      "source": [
        "%%capture captured_output_Faithfulness\n",
        "## 评估Faithfulness\n",
        "import pandas as pd\n",
        "\n",
        "# 创建包含结果的DataFrame\n",
        "results_df_Faithfulness = pd.DataFrame(columns=[\"Embedding Model\", \"Rerank Model\", \"Average_Faithfulness_Score\"])\n",
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "from llama_index.core.indices.query.schema import QueryBundle, QueryType\n",
        "from typing import List\n",
        "from llama_index.core.schema import NodeWithScore\n",
        "results_df = pd.DataFrame()\n",
        "from llama_index.core.retrievers import (\n",
        "    BaseRetriever,\n",
        "    VectorIndexRetriever,\n",
        ")\n",
        "from llama_index.core.query_engine import RetrieverQueryEngine\n",
        "\n",
        "from deepeval.integrations.llama_index import DeepEvalAnswerRelevancyEvaluator\n",
        "from deepeval.integrations.llama_index import DeepEvalFaithfulnessEvaluator\n",
        "from deepeval.integrations.llama_index import DeepEvalContextualRelevancyEvaluator\n",
        "\n",
        "# Loop over embeddings\n",
        "for embed_name, embed_model in EMBEDDINGS.items():\n",
        "\n",
        "    service_context = ServiceContext.from_defaults(llm=None, embed_model=embed_model)\n",
        "    vector_index = VectorStoreIndex(nodes, service_context=service_context)\n",
        "    vector_retriever = VectorIndexRetriever(index=vector_index, similarity_top_k = 10)\n",
        "\n",
        "\n",
        "    # Loop over rerankers\n",
        "    for rerank_name, reranker in RERANKERS.items():\n",
        "\n",
        "        print(f\"Running Evaluation for Embedding Model: {embed_name} and Reranker: {rerank_name}\")\n",
        "\n",
        "        # Define Retriever\n",
        "        class CustomRetriever(BaseRetriever):\n",
        "            \"\"\"Custom retriever that performs both Vector search and Knowledge Graph search\"\"\"\n",
        "\n",
        "            def __init__(\n",
        "                self,\n",
        "                vector_retriever: VectorIndexRetriever,\n",
        "            ) -> None:\n",
        "                \"\"\"Init params.\"\"\"\n",
        "                self._vector_retriever = vector_retriever\n",
        "\n",
        "            def _retrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]:\n",
        "                \"\"\"Retrieve nodes given query.\"\"\"\n",
        "                retrieved_nodes = self._vector_retriever.retrieve(query_bundle)\n",
        "                if reranker != 'None':\n",
        "                    retrieved_nodes = reranker.postprocess_nodes(retrieved_nodes, query_bundle)\n",
        "                else:\n",
        "                    retrieved_nodes = retrieved_nodes[:5]\n",
        "                return retrieved_nodes\n",
        "\n",
        "            async def _aretrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]:\n",
        "                return self._retrieve(query_bundle)\n",
        "            async def aretrieve(self, str_or_query_bundle: QueryType) -> List[NodeWithScore]:\n",
        "                if isinstance(str_or_query_bundle, str):\n",
        "                    str_or_query_bundle = QueryBundle(str_or_query_bundle)\n",
        "                return self._aretrieve(str_or_query_bundle)\n",
        "\n",
        "        custom_retriever = CustomRetriever(vector_retriever)\n",
        "        query_engine = RetrieverQueryEngine.from_args(custom_retriever)\n",
        "        # query_engine = custom_retriever.as_query_engine()\n",
        "        queries_list = list(test_dataset.queries.values())\n",
        "\n",
        "        faithfulness_scores = []\n",
        "\n",
        "        for query in queries_list:\n",
        "            response_object =query_engine.query(query)\n",
        "            faithfulness_evaluator = DeepEvalFaithfulnessEvaluator(\n",
        "            threshold=0.5,\n",
        "            model=\"gpt-4\",\n",
        "            include_reason=False)\n",
        "\n",
        "            evaluation_result_faithfulness = faithfulness_evaluator.evaluate_response(\n",
        "                query=query,\n",
        "                response=response_object\n",
        "            )\n",
        "\n",
        "            faithfulness_scores.append(evaluation_result_faithfulness.score)\n",
        "        # Calculate averages\n",
        "        average_faithfulness_score = sum(faithfulness_scores) / len(faithfulness_scores)\n",
        "\n",
        "        current_df = pd.DataFrame({\"Embedding Model\": embed_name, \"Rerank Model\": rerank_name, \"Average_Faithfulness_Score\": average_faithfulness_score}, index=[0])\n",
        "        results_df_Faithfulness = pd.concat([results_df_Faithfulness, current_df], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a0cd966103718c6",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-22T08:51:09.454213Z",
          "start_time": "2024-04-22T08:51:09.450845Z"
        },
        "id": "9a0cd966103718c6",
        "outputId": "28675461-892a-44d3-fa38-40c6c608d799"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Embedding Model     Rerank Model  Average_Faithfulness_Score\n",
            "0          OpenAI  WithoutReranker                         1.0\n"
          ]
        }
      ],
      "source": [
        "print(results_df_Faithfulness)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef8c6862",
      "metadata": {
        "id": "ef8c6862"
      },
      "outputs": [],
      "source": [
        "results_df_Faithfulness.to_csv('Faithfulness.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ef4343d",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-22T08:52:11.742737Z",
          "start_time": "2024-04-22T08:51:56.068880Z"
        },
        "id": "6ef4343d"
      },
      "outputs": [],
      "source": [
        "%%capture captured_output_AnswerRelevancy\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# 创建包含结果的DataFrame\n",
        "results_df_AnswerRelevancy = pd.DataFrame(columns=[\"Embedding Model\", \"Rerank Model\", \"Average AnswerRelevancy Score\"])\n",
        "\n",
        "## 评估AnswerRelevancy\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "from llama_index.core.indices.query.schema import QueryBundle, QueryType\n",
        "from typing import List\n",
        "from llama_index.core.schema import NodeWithScore\n",
        "results_df = pd.DataFrame()\n",
        "from llama_index.core.retrievers import (\n",
        "    BaseRetriever,\n",
        "    VectorIndexRetriever,\n",
        ")\n",
        "from llama_index.core.query_engine import RetrieverQueryEngine\n",
        "\n",
        "from deepeval.integrations.llama_index import DeepEvalAnswerRelevancyEvaluator\n",
        "from deepeval.integrations.llama_index import DeepEvalFaithfulnessEvaluator\n",
        "from deepeval.integrations.llama_index import DeepEvalContextualRelevancyEvaluator\n",
        "\n",
        "# Loop over embeddings\n",
        "for embed_name, embed_model in EMBEDDINGS.items():\n",
        "\n",
        "    service_context = ServiceContext.from_defaults(llm=None, embed_model=embed_model)\n",
        "    vector_index = VectorStoreIndex(nodes, service_context=service_context)\n",
        "    vector_retriever = VectorIndexRetriever(index=vector_index, similarity_top_k = 10)\n",
        "\n",
        "\n",
        "    # Loop over rerankers\n",
        "    for rerank_name, reranker in RERANKERS.items():\n",
        "\n",
        "        print(f\"Running Evaluation for Embedding Model: {embed_name} and Reranker: {rerank_name}\")\n",
        "\n",
        "        # Define Retriever\n",
        "        class CustomRetriever(BaseRetriever):\n",
        "            \"\"\"Custom retriever that performs both Vector search and Knowledge Graph search\"\"\"\n",
        "\n",
        "            def __init__(\n",
        "                self,\n",
        "                vector_retriever: VectorIndexRetriever,\n",
        "            ) -> None:\n",
        "                \"\"\"Init params.\"\"\"\n",
        "                self._vector_retriever = vector_retriever\n",
        "\n",
        "            def _retrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]:\n",
        "                \"\"\"Retrieve nodes given query.\"\"\"\n",
        "                retrieved_nodes = self._vector_retriever.retrieve(query_bundle)\n",
        "                if reranker != 'None':\n",
        "                    retrieved_nodes = reranker.postprocess_nodes(retrieved_nodes, query_bundle)\n",
        "                else:\n",
        "                    retrieved_nodes = retrieved_nodes[:5]\n",
        "                return retrieved_nodes\n",
        "\n",
        "            async def _aretrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]:\n",
        "                return self._retrieve(query_bundle)\n",
        "            async def aretrieve(self, str_or_query_bundle: QueryType) -> List[NodeWithScore]:\n",
        "                if isinstance(str_or_query_bundle, str):\n",
        "                    str_or_query_bundle = QueryBundle(str_or_query_bundle)\n",
        "                return self._aretrieve(str_or_query_bundle)\n",
        "\n",
        "        custom_retriever = CustomRetriever(vector_retriever)\n",
        "        query_engine = RetrieverQueryEngine.from_args(custom_retriever)\n",
        "        # query_engine = custom_retriever.as_query_engine()\n",
        "        queries_list = list(test_dataset.queries.values())\n",
        "\n",
        "        answer_relevancy_scores = []\n",
        "        faithfulness_scores = []\n",
        "        contextual_relevancy_scores = []\n",
        "\n",
        "        for query in queries_list:\n",
        "            response_object =query_engine.query(query)\n",
        "\n",
        "            answer_relevancy_evaluator = DeepEvalAnswerRelevancyEvaluator(\n",
        "            threshold=0.5,\n",
        "            model=\"gpt-4\",\n",
        "            include_reason=False)\n",
        "\n",
        "\n",
        "            evaluation_result_answer_relevancy = answer_relevancy_evaluator.evaluate_response(\n",
        "                query=query,\n",
        "                response=response_object\n",
        "            )\n",
        "            answer_relevancy_scores.append(evaluation_result_answer_relevancy.score)\n",
        "\n",
        "        # Calculate averages\n",
        "        average_answer_relevancy_score = sum(answer_relevancy_scores) / len(answer_relevancy_scores)\n",
        "\n",
        "        current_df = pd.DataFrame({\"Embedding Model\": embed_name, \"Rerank Model\": rerank_name, \"Average AnswerRelevancy Score\": average_answer_relevancy_score}, index=[0])\n",
        "\n",
        "        results_df_AnswerRelevancy = pd.concat([results_df_AnswerRelevancy, current_df], ignore_index=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "213ef86ae1081b69",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-22T08:52:29.710227Z",
          "start_time": "2024-04-22T08:52:29.706346Z"
        },
        "id": "213ef86ae1081b69",
        "outputId": "20ff305a-5546-4d46-da5c-eea2713f86ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Embedding Model     Rerank Model  Average AnswerRelevancy Score\n",
            "0          OpenAI  WithoutReranker                            1.0\n"
          ]
        }
      ],
      "source": [
        "print(results_df_AnswerRelevancy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d24b504a",
      "metadata": {
        "id": "d24b504a"
      },
      "outputs": [],
      "source": [
        "results_df_AnswerRelevancy.to_csv('AnswerRelevancy.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}